---
title: "education project"
output: git_hub document 
date: "2023-06-12"
---
```{r}
library(ipumsr)
library(dplyr)
library(lmtest)
library(fastDummies)
library(sandwich)

```
```{r}
setwd("C:/Users/gealy/OneDrive/Documents/git/educationimmigrantswages")
ddi <- read_ipums_ddi("usa_00005.xml")
data <- read_ipums_micro(ddi)
```

```{r}
finaldata <- data %>% 
  mutate(EDUCD_recoded = case_when(
    EDUCD %in% c(0, 1) ~ NA_real_,  # N/A or no schooling
    EDUCD == 2 ~ 0,  # No schooling completed
    EDUCD %in% 10:14 ~ 1,  # Nursery school to grade 4
    EDUCD %in% 20:26 ~ 5,  # Grade 5, 6, 7, or 8
    EDUCD == 30 ~ 9,  # Grade 9
    EDUCD == 40 ~ 10,  # Grade 10
    EDUCD == 50 ~ 11,  # Grade 11
    EDUCD %in% 60:64 ~ 12,  # Grade 12 or High school graduate or GED
    EDUCD == 65 ~ 12.5,  # Some college, but less than 1 year
    EDUCD %in% 70:83 ~ 13,  # 1 year of college to Associate's degree
    EDUCD == 90 ~ 15,  # 3 years of college
    EDUCD %in% 100:113 ~ 16,  # 4 years of college to Bachelor's degree
    EDUCD %in% 114:115 ~ 17.5,  # Master's degree
    EDUCD == 116 ~ 22,  # Doctoral degree
    EDUCD == 999 ~ NA_real_,  # Missing
    TRUE ~ NA_real_  # Other cases
  ))

```



```{r}
finaldata$potentialexperience=finaldata$AGE-16
```


```{r}
finaldata=finaldata%>%filter(AGE>=18&AGE<66)%>%filter(UHRSWORK>29)%>%filter(INCWAGE>0)%>%filter(WKSWORK1>=30)%>%filter(YRIMMIG==0|AGE -(2000-YRIMMIG)<= EDUCD_recoded +6)%>%filter(potentialexperience<41)
```
```{r}
#combine the states of the US into one value 
finaldata$bplusone <- ifelse(finaldata$BPL < 150, 1, finaldata$BPL)
```
```{r}
finaldata$SEX=ifelse(finaldata$SEX==2,0,finaldata$SEX)
```

```{r}
#perpare the additional variables 
finaldata$wages=finaldata$INCWAGE/(finaldata$WKSWORK1*finaldata$UHRSWORK)

```
```{r}
finaldata <- finaldata %>%
  dummy_cols(select_columns = 'DISABWRK') %>%
  dummy_cols(select_columns = 'REGION', remove_first_dummy = TRUE)%>%dummy_cols(select_columns = 'CITIZEN', remove_first_dummy = TRUE)

```
```{r}
finaldata$REGION4142=ifelse(finaldata$REGION==41 |finaldata$REGION==42,1,0)
```
```{r}
finaldata=finaldata %>%
  mutate(z_scores = as.vector(scale(wages))) %>%
   group_by(bplusone) %>%
  filter(abs(z_scores) < 3)
 
```

```{r}
finaldata$METROc=ifelse(finaldata$METRO==1,1,0)
```
```{r}
finaldata$SPEAKENGc=ifelse(finaldata$SPEAKENG==1|finaldata$SPEAKENG==6,1,0)
```
```{r}
finaldata$CITIZENc=ifelse(finaldata$CITIZEN==1|finaldata$CLUSTER==2,1,0)
```
```{r}
finaldata$hsgrad=ifelse(finaldata$EDUCD_recoded<13,0,1)
```
```{r}

```






```{r}

# Initialize an empty list to store the models and coeftests
bigmodels <- list()
bigcoeftests <- list()

# Count the number of records for each country
country_counts <- table(finaldata$bplusone)

# Get only the countries with more than one record
countries <- as.numeric(names(country_counts[country_counts > 1]))

# Initialize a list to store the country codes
bigcountry_codes <- c()
# Loop over each country
for (country in countries) {
  
  # Subset the data for the current country
  country_data <- subset(finaldata, bplusone == country)
  
  # Check if there are any non-NA rows
  if (sum(complete.cases(country_data)) > 0) {
    
    # Fit the model
  bigmodels[[length(bigmodels) + 1]] <- lm(log(wages) ~ EDUCD_recoded+SEX+poly(potentialexperience,degree = 4,raw = T)+hsgrad, data = country_data)
    
    # Perform coeftest with robust standard errors and store the result
    bigcoeftests[[length(bigcoeftests) + 1]] <- coeftest(bigmodels[[length(bigmodels)]], vcov = vcovHC(bigmodels[[length(bigmodels)]], type = "HC1"))
    
    # Store the country code
    bigcountry_codes <- c(bigcountry_codes, country)
  }
}

# Set the names of the models and coeftests lists
names(bigmodels) <- bigcountry_codes
names(bigcoeftests) <- bigcountry_codes

# Create a dataframe with country codes
df <- data.frame(CountryCode = bigcountry_codes, stringsAsFactors = FALSE)



```
```{r}
  # Store the country codes and names as a character vector
country_info <- c(
  "1\tUnited States",
  "150\tCanada",
  "155\tSt. Pierre and Miquelon",
  "160\tAtlantic Islands",
  "199\tNorth America, ns",
  "200\tMexico",
  "210\tCentral America",
  "250\tCuba",
  "260\tWest Indies",
  "299\tAmericas, n.s.",
  "300\tSOUTH AMERICA",
  "400\tDenmark",
  "401\tFinland",
  "402\tIceland",
  "403\tLapland, n.s.",
  "404\tNorway",
  "405\tSweden",
  "410\tEngland",
  "411\tScotland",
  "412\tWales",
  "413\tUnited Kingdom, ns",
  "414\tIreland",
  "419\tNorthern Europe, ns",
  "420\tBelgium",
  "421\tFrance",
  "422\tLiechtenstein",
  "423\tLuxembourg",
  "424\tMonaco",
  "425\tNetherlands",
  "426\tSwitzerland",
  "429\tWestern Europe, ns",
  "430\tAlbania",
  "431\tAndorra",
  "432\tGibraltar",
  "433\tGreece",
  "434\tItaly",
  "435\tMalta",
  "436\tPortugal",
  "437\tSan Marino",
  "438\tSpain",
  "439\tVatican City",
  "440\tSouthern Europe, ns",
  "450\tAustria",
  "451\tBulgaria",
  "452\tCzechoslovakia",
  "453\tGermany",
  "454\tHungary",
  "455\tPoland",
  "456\tRomania",
  "457\tYugoslavia",
  "458\tCentral Europe, ns",
  "459\tEastern Europe, ns",
  "460\tEstonia",
  "461\tLatvia",
  "462\tLithuania",
  "463\tBaltic States, ns",
  "465\tOther USSR/Russia",
  "499\tEurope, ns",
  "500\tChina",
  "501\tJapan",
  "502\tKorea",
  "509\tEast Asia, ns",
  "510\tBrunei",
  "511\tCambodia (Kampuchea)",
  "512\tIndonesia",
  "513\tLaos",
  "514\tMalaysia",
  "515\tPhilippines",
  "516\tSingapore",
  "517\tThailand",
  "518\tVietnam",
  "519\tSoutheast Asia, ns",
  "520\tAfghanistan",
  "521\tIndia",
  "522\tIran",
  "523\tMaldives",
  "524\tNepal",
  "530\tBahrain",
  "531\tCyprus",
  "532\tIraq",
  "533\tIraq/Saudi Arabia",
  "534\tIsrael/Palestine",
  "535\tJordan",
  "536\tKuwait",
  "537\tLebanon",
  "538\tOman",
  "539\tQatar",
  "540\tSaudi Arabia",
  "541\tSyria",
  "542\tTurkey",
  "543\tUnited Arab Emirates",
  "544\tYemen Arab Republic (North)",
  "545\tYemen, PDR (South)",
  "546\tPersian Gulf States, n.s.",
  "547\tMiddle East, ns",
"548\tSouthwest Asia, nec/ns",
  "549\tAsia Minor, ns",
  "550\tSouth Asia, nec",
  "599\tAsia, nec/ns",
  "600\tAFRICA",
  "700\tAustralia and New Zealand",
  "710\tPacific Islands",
  "800\tAntarctica, ns/nec",
  "900\tAbroad (unknown) or at sea",
  "950\tOther n.e.c.",
  "999\tMissing/blank"
)

# Split each line into a country code and name
country_info_split <- strsplit(country_info, "\t")

# Extract the country codes and names into separate vectors
country_codes <- sapply(country_info_split, "[[", 1)
country_names <- sapply(country_info_split, "[[", 2)

# Create a dataframe with the country codes and names
df <- data.frame(
  CountryCode = as.numeric(country_codes),
  CountryName = country_names,
  stringsAsFactors = FALSE
)

```

```{r}

  # Initialize a list to store the confidence intervals
ci <- list()

# Initialize a list to store the coefficients
coefs <- list()

# Loop over each model
for (i in 1:length(bigmodels)) {
  
  # Get the standard error for EDUCD_RECODED
  se <- sqrt(vcovHC(bigmodels[[i]], type = "HC1")["EDUCD_recoded", "EDUCD_recoded"])
  
  # Get the coefficient for EDUCD_RECODED
  coef <- bigmodels[[i]]$coefficients["EDUCD_recoded"]
  
  # Store the coefficient
  coefs[[i]] <- coef
  
  # Calculate the confidence interval
  ci[[i]] <- coef + c(-1, 1) * 1.96 * se
}



# Set the names of the confidence intervals and coefficients lists
names(ci) <- bigcountry_codes
names(coefs) <- bigcountry_codes

# Sort ci, coefs, and country_info according to bigcountry_codes
ci <- ci[match(bigcountry_codes, names(ci))]
coefs <- coefs[match(bigcountry_codes, names(coefs))]

# Get the country codes for which you have coefficients
valid_country_codes <- names(coefs)

# Split country_info into a list where each element is a vector with the country code and the country name
country_info_split <- strsplit(country_info, "\t")

# Create a named vector with country names, where the names are the country codes
country_info <- setNames(sapply(country_info_split, `[[`, 2), sapply(country_info_split, `[[`, 1))

# Now, create country_info_sorted
country_info_sorted <- country_info[valid_country_codes]

# Create your final data frame
df2 <- data.frame(
  CountryInfo = country_info_sorted,
  Coefficient = unlist(coefs),
  LowerBound = sapply(ci, "[[", 1),
  UpperBound = sapply(ci, "[[", 2)
)











```
```{r}
df2$uminusl=df2$UpperBound-df2$LowerBound
```
```{r}

# Get counts of all unique values in finaldata$bplusone
counts <- table(finaldata$bplusone)

# Subselect the counts for row.names(df2)
df2$samplesize <- counts[row.names(df2)]

# Replace NA values with 0 if required
df2$samplesize[is.na(df2$samplesize)] <- 0


```
```{r}
# Initialize a list to store the adjusted R-squared values
  # Initialize a list to store the adjusted R-squared values
adj_r_squared <- list()

# Loop over each model
for (i in 1:length(bigmodels)) {
  
  # Get the model residuals
  residuals <- bigmodels[[i]]$residuals
  
  # Get the model fitted values
  fitted <- bigmodels[[i]]$fitted.values
  
  # Get the specific country's wages
  country_wages <- finaldata$wages[finaldata$bplusone == bigcountry_codes[i]]
  
  # Compute the total sum of squares
  tss <- sum((country_wages - mean(country_wages))^2)
  
  # Compute the residual sum of squares
  rss <- sum(residuals^2)
  
  # Compute R-squared
  rsq <- 1 - rss / tss
  
  # Get the number of observations for the current model
  n <- length(bigmodels[[i]]$residuals)
  
  # Get the number of predictors for the current model
  p <- length(bigmodels[[i]]$coefficients) - 1  # subtract 1 for the intercept
  
  # Calculate the adjusted R-squared value for the current model
  adj_r_squared[[i]] <- 1 - (1 - rsq) * (n - 1) / (n - p - 1)
}

# Set the names of the adjusted R-squared list
names(adj_r_squared) <- bigcountry_codes

# Sort adj_r_squared according to bigcountry_codes
adj_r_squared <- adj_r_squared[match(bigcountry_codes, names(adj_r_squared))]

# Add the adjusted R-squared values as a new column to the data frame
df2$AdjRSquared <- unlist(adj_r_squared)

```











